{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dataset import Quora\n",
    "import numpy as np\n",
    "\n",
    "from chainer import optimizers\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "import chainer \n",
    "from tqdm import tqdm\n",
    "\n",
    "from sobamchan.sobamchan_vocabulary import Vocabulary\n",
    "from sobamchan.sobamchan_utility import Utility\n",
    "from sobamchan.sobamchan_chainer import Model\n",
    "from sobamchan.sobamchan_log import Log\n",
    "from sobamchan.sobamchan_iterator import Iterator\n",
    "util = Utility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TestModel(Model):\n",
    "    def __init__(self, class_n, vocab_n, d, vocab):\n",
    "        super(TestModel, self).__init__(\n",
    "            embed=L.EmbedID(vocab_n, d),\n",
    "            fc1=L.Linear(None, 10),\n",
    "            fc2=L.Linear(None, 10),\n",
    "            fc3=L.Linear(None, class_n),\n",
    "        )\n",
    "    def __call__(self, x, t, train=True):\n",
    "        x = self.fwd(x, train)\n",
    "        return F.softmax_cross_entropy(x, t), F.accuracy(x, t)\n",
    "    def fwd(self, x, train):\n",
    "        q1 = x[:, 0, :]\n",
    "        q2 = x[:, 1, :]\n",
    "        embed1 = self.embed(q1)\n",
    "        embed2 = self.embed(q2)\n",
    "        h = F.concat([embed1, embed2])\n",
    "        h = F.tanh(self.fc1(h))\n",
    "        h = F.tanh(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-55556b10c966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-55556b10c966>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sochan/.pyenv/versions/3.5.2/envs/nlp/lib/python3.5/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad)\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0mgxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sochan/.pyenv/versions/3.5.2/envs/nlp/lib/python3.5/site-packages/chainer/functions/connection/linear.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, inputs, grad_outputs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mgW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sochan/.pyenv/versions/3.5.2/envs/nlp/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(args):\n",
    "    \n",
    "    bs = 256\n",
    "    epoch = 3\n",
    "    gpu = -1\n",
    "    opath = './test'\n",
    "    \n",
    "    \n",
    "    train_x, train_t, test_x, test_t = Quora().get()\n",
    "    train_n = len(train_x)\n",
    "    test_n = len(test_x)\n",
    "    \n",
    "    vocab = Vocabulary()\n",
    " \n",
    "    for d in train_x + test_x:\n",
    "        try:\n",
    "            vocab.new(d[0])\n",
    "            vocab.new(d[1])\n",
    "        except:\n",
    "            print(d)\n",
    "            break\n",
    "\n",
    "    train_x = np.array([tuple([util.pad_to_max(vocab.encode(x[0].lower()), 30, 0), util.pad_to_max(vocab.encode(x[1].lower()), 30, 0)]) for x in train_x])\n",
    "    train_t = np.array(train_t)\n",
    "    test_x  = np.array([tuple([util.pad_to_max(vocab.encode(x[0].lower()), 30, 0), util.pad_to_max(vocab.encode(x[1].lower()), 30, 0)]) for x in test_x])\n",
    "    test_t = np.array(test_t)\n",
    "    \n",
    "    optimizer = args['optimizer']\n",
    "    class_n = 2\n",
    "    vocab_n = len(vocab)\n",
    "    d = 300\n",
    "    model = args['model'](class_n, vocab_n, d, vocab)\n",
    "    xp = model.check_gpu(gpu)\n",
    "    optimizer.setup(model)\n",
    "    \n",
    "    train_loss_log = Log()\n",
    "    test_loss_log = Log()\n",
    "    test_acc_log = Log()\n",
    "    \n",
    "    for _ in tqdm(range(epoch)):\n",
    "        \n",
    "        order = np.random.permutation(train_n)\n",
    "        train_x_iter = Iterator(train_x, bs, order, shuffle=False)\n",
    "        train_t_iter = Iterator(train_t, bs, order, shuffle=False)\n",
    "        \n",
    "        loss_sum = 0\n",
    "        for x, t in zip(train_x_iter, train_t_iter):\n",
    "            model.cleargrads()\n",
    "            x_n = len(x)\n",
    "            x = model.prepare_input(x, dtype=xp.int32, xp=xp)\n",
    "            t = model.prepare_input(t, dtype=np.int32, xp=xp)\n",
    "            loss, _ = model(x, t, train=True)\n",
    "            loss_sum += loss.data * x_n\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "        loss_mean = float(loss_sum/train_n)\n",
    "        train_loss_log.add(loss_mean)\n",
    "        print('train_loss: {}'.format(loss_mean))\n",
    "        \n",
    "        order = np.random.permutation(test_n)\n",
    "        test_x_iter = Iterator(test_x, bs, order, shuffle=False)\n",
    "        test_t_iter = Iterator(test_t, bs, order, shuffle=False)\n",
    "        loss_sum = 0\n",
    "        acc_sum = 0\n",
    "        for x, t in zip(test_x_iter, test_t_iter):\n",
    "            model.cleargrads()\n",
    "            x_n = len(x)\n",
    "            x = model.prepare_input(x, dtype=xp.int32, xp=xp)\n",
    "            t = model.prepare_input(t, dtype=xp.int32, xp=xp)\n",
    "            loss, acc = model(x, t, train=False)\n",
    "            loss_sum += loss.data * x_n\n",
    "            acc_sum += acc.data * x_n\n",
    "        loss_mean = float(loss_sum / test_n)\n",
    "        acc_mean = float(acc_sum / test_n)\n",
    "        test_loss_log.add(loss_mean)\n",
    "        test_acc_log.add(acc_mean)\n",
    "        print('test loss: {}'.format(loss_mean))\n",
    "        print('test acc: {}'.format(acc_mean))\n",
    "\n",
    "        \n",
    "    opath = './results/{}'.format(opath)\n",
    "    if not os.path.exists(opath):\n",
    "        os.mkdir(opath)\n",
    "        \n",
    "\n",
    "    train_loss_log.save('{}/train_loss_log'.format(opath))\n",
    "    train_loss_log.save_graph('{}/train_loss_log'.format(opath))\n",
    "    test_loss_log.save('{}/test_loss_log'.format(opath))\n",
    "    test_loss_log.save_graph('{}/test_loss_log'.format(opath))\n",
    "    test_acc_log.save('{}/test_acc_log'.format(opath))\n",
    "    test_acc_log.save_graph('{}/test_acc_log'.format(opath))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "args = {}\n",
    "args['optimizer'] = optimizers.AdaGrad()\n",
    "args['model'] = TestModel\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
